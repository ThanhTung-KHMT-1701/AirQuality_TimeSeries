{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1f0189",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993ae321",
   "metadata": {
    "papermill": {
     "duration": 0.00502,
     "end_time": "2026-01-20T00:20:51.534423",
     "exception": false,
     "start_time": "2026-01-20T00:20:51.529403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Topic 1:  Regression vs ARIMA\n",
    "\n",
    "Ch·ªß ƒë·ªÅ 1: Regression vs ARIMA ‚Äì khi n√†o ch·ªçn c√°i n√†o?\n",
    "Trong ch·ªß ƒë·ªÅ n√†y, m·ªói nh√≥m gi·ªØ nguy√™n pipeline hi·ªán t·∫°i v√† ch·ªâ so s√°nh hai h∆∞·ªõng d·ª± b√°o ƒë√£ c√≥: baseline h·ªìi quy\n",
    "(d√πng time features v√† lag features) v√† ARIMA (m√¥ h√¨nh chu·ªói th·ªùi gian ƒë∆°n bi·∫øn). Y√™u c·∫ßu quan tr·ªçng nh·∫•t l√† so s√°nh\n",
    "ph·∫£i c√¥ng b·∫±ng:\n",
    "+ C√πng m·ªôt tr·∫°m (v√≠ d·ª• Aotizhongxin).\n",
    "+ C√πng m·ªëc chia train/test theo th·ªùi gian b·∫±ng CUTOFF.\n",
    "+ C√πng horizon (ƒë·∫∑c bi·ªát l√† horizon=1).\n",
    "\n",
    "Sau khi ch·∫°y xong hai m√¥ h√¨nh, nh√≥m ph·∫£i tr·∫£ l·ªùi ba c√¢u.\n",
    "1. M√¥ h√¨nh n√†o t·ªët h∆°n cho horizon=1?: ·ªü ƒë√¢y sinh vi√™n c·∫ßn d·ª±a v√†o s·ªë li·ªáu MAE/RMSE v√† gi·∫£i th√≠ch ƒë∆∞·ª£c v√¨ sao\n",
    "d·ª± b√°o r·∫•t ng·∫Øn h·∫°n th∆∞·ªùng b·ªã chi ph·ªëi m·∫°nh b·ªüi ƒë·ªô tr·ªÖ g·∫ßn nh∆∞ PM2.5_lag1, khi·∫øn regression baseline th∆∞·ªùng\n",
    "b√°m s√°t t·ªët n·∫øu feature engineering ƒë√∫ng, trong khi ARIMA c≈©ng c√≥ th·ªÉ t·ªët nh∆∞ng ph·ª• thu·ªôc v√†o c·∫•u tr√∫c t·ª±\n",
    "t∆∞∆°ng quan v√† quy·∫øt ƒë·ªãnh sai ph√¢n.\n",
    "\n",
    "2. M√¥ h√¨nh n√†o ·ªïn h∆°n khi c√≥ spike?: nh√≥m ph·∫£i ch·ªçn m·ªôt ƒëo·∫°n th·ªùi gian c√≥ ƒë·ªânh PM2.5 r√µ (1‚Äì3 ng√†y), v·∫Ω forecast\n",
    "vs actual c·ªßa c·∫£ hai m√¥ h√¨nh tr√™n c√πng ƒëo·∫°n ƒë√≥, r·ªìi ph√¢n t√≠ch m√¥ h√¨nh n√†o ph·∫£n ·ª©ng nhanh h∆°n ho·∫∑c b·ªã m∆∞·ª£t h√≥a\n",
    "qu√° m·ª©c; ƒë·ªìng th·ªùi li√™n h·ªá v·ªõi s·ª± kh√°c nhau gi·ªØa RMSE v√† MAE, v√¨ RMSE s·∫Ω tƒÉng m·∫°nh n·∫øu m√¥ h√¨nh sai n·∫∑ng\n",
    "·ªü m·ªôt v√†i th·ªùi ƒëi·ªÉm spike.\n",
    "\n",
    "3. N·∫øu tri·ªÉn khai th·∫≠t, b·∫°n ch·ªçn g√¨ v√† v√¨ sao?: c√¢u n√†y kh√¥ng ch·ªâ d·ª±a tr√™n ƒëi·ªÉm s·ªë m√† c√≤n d·ª±a tr√™n b·ªëi c·∫£nh v·∫≠n\n",
    "h√†nh: regression baseline th∆∞·ªùng d·ªÖ m·ªü r·ªông khi mu·ªën th√™m ƒë·∫∑c tr∆∞ng, d·ªÖ c·∫≠p nh·∫≠t v√† ch·∫°y nhanh, c√≤n ARIMA\n",
    "c√≥ ∆∞u th·∫ø v·ªÅ gi·∫£i th√≠ch theo (ùëù, ùëë, ùëû) v√† c√≥ th·ªÉ k√®m kho·∫£ng tin c·∫≠y; n·∫øu m·ª•c ti√™u l√† c·∫£nh b√°o s·ªõm trong ƒëi·ªÅu ki·ªán\n",
    "th·ªùi ti·∫øt bi·∫øn ƒë·ªông m·∫°nh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c3942",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6192e6af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:20:51.548804Z",
     "iopub.status.busy": "2026-01-20T00:20:51.548804Z",
     "iopub.status.idle": "2026-01-20T00:20:55.822373Z",
     "shell.execute_reply": "2026-01-20T00:20:55.822373Z"
    },
    "papermill": {
     "duration": 4.285583,
     "end_time": "2026-01-20T00:20:55.822373",
     "exception": true,
     "start_time": "2026-01-20T00:20:51.536790",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOPIC 1: REGRESSION vs ARIMA - So s√°nh c√¥ng b·∫±ng\n",
      "============================================================\n",
      "\n",
      "üìç Tr·∫°m: Aotizhongxin\n",
      "üìÖ CUTOFF: 2017-01-01\n",
      "üéØ Horizon: 1 gi·ªù\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/04_regression_predictions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müéØ Horizon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHORIZON\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m gi·ªù\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Load Regression Predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m reg_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/processed/04_regression_predictions.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m reg_df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(reg_df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     50\u001b[39m reg_df = reg_df[reg_df[\u001b[33m'\u001b[39m\u001b[33mstation\u001b[39m\u001b[33m'\u001b[39m] == STATION].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\KhaiPhaDuLieu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    899\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    900\u001b[39m     dialect,\n\u001b[32m    901\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    908\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    909\u001b[39m )\n\u001b[32m    910\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\KhaiPhaDuLieu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    574\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\KhaiPhaDuLieu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1404\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1406\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1407\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\KhaiPhaDuLieu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1659\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1660\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1672\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\KhaiPhaDuLieu\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    855\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    856\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    857\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    858\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    867\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    868\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/processed/04_regression_predictions.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# SETUP: Colors & Style theo y√™u c·∫ßu\n",
    "# ============================================================\n",
    "COLOR_BLUE = \"#1F62FF\"\n",
    "COLOR_BLUE_LIGHT = \"#1FD2FF\"\n",
    "COLOR_RED = \"#FF351F\" \n",
    "COLOR_GREEN = \"#1FFF2A\"\n",
    "COLOR_ORANGE = \"#FF9A1F\"\n",
    "COLOR_PURPLE = \"#9E1FFF\"\n",
    "COLOR_YELLOW = \"#FFDA1F\"\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Create images folder\n",
    "if not os.path.exists('../images'):\n",
    "    os.makedirs('../images')\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA - ƒê·∫£m b·∫£o c√¥ng b·∫±ng: c√πng tr·∫°m, c√πng CUTOFF\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"TOPIC 1: REGRESSION vs ARIMA - So s√°nh c√¥ng b·∫±ng\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Parameters\n",
    "STATION = 'Aotizhongxin'\n",
    "CUTOFF = '2017-01-01'\n",
    "HORIZON = 1\n",
    "\n",
    "print(f\"\\nüìç Tr·∫°m: {STATION}\")\n",
    "print(f\"üìÖ CUTOFF: {CUTOFF}\")\n",
    "print(f\"üéØ Horizon: {HORIZON} gi·ªù\")\n",
    "\n",
    "# Load Regression Predictions\n",
    "reg_df = pd.read_csv('../data/processed/04_regression_predictions.csv')\n",
    "reg_df['datetime'] = pd.to_datetime(reg_df['datetime'])\n",
    "reg_df = reg_df[reg_df['station'] == STATION].copy()\n",
    "reg_df.set_index('datetime', inplace=True)\n",
    "reg_df = reg_df.rename(columns={'y_true': 'Actual_Reg', 'y_pred': 'Regression'})\n",
    "\n",
    "# Load ARIMA Predictions\n",
    "arima_df = pd.read_csv('../data/processed/05_arima_pm25_predictions.csv')\n",
    "arima_df['datetime'] = pd.to_datetime(arima_df['datetime'])\n",
    "arima_df.set_index('datetime', inplace=True)\n",
    "arima_df = arima_df.rename(columns={'y_true': 'Actual_ARIMA', 'y_pred': 'ARIMA'})\n",
    "\n",
    "print(f\"\\nüìä Regression predictions: {len(reg_df)} rows\")\n",
    "print(f\"üìä ARIMA predictions: {len(arima_df)} rows\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. ALIGN DATA - ƒê·∫£m b·∫£o so s√°nh tr√™n c√πng kho·∫£ng th·ªùi gian\n",
    "# ============================================================\n",
    "# T√¨m kho·∫£ng th·ªùi gian chung\n",
    "common_start = max(reg_df.index.min(), arima_df.index.min())\n",
    "common_end = min(reg_df.index.max(), arima_df.index.max())\n",
    "\n",
    "print(f\"\\nüîó Kho·∫£ng th·ªùi gian chung: {common_start} ƒë·∫øn {common_end}\")\n",
    "\n",
    "# T·∫°o DataFrame so s√°nh\n",
    "comparison_df = pd.DataFrame(index=pd.date_range(common_start, common_end, freq='H'))\n",
    "comparison_df = comparison_df.join(reg_df[['Actual_Reg', 'Regression']])\n",
    "comparison_df = comparison_df.join(arima_df[['Actual_ARIMA', 'ARIMA']])\n",
    "\n",
    "# S·ª≠ d·ª•ng Actual t·ª´ Regression (c·∫£ 2 n√™n gi·ªëng nhau)\n",
    "comparison_df['Actual'] = comparison_df['Actual_Reg'].fillna(comparison_df['Actual_ARIMA'])\n",
    "comparison_df = comparison_df.dropna(subset=['Actual', 'Regression', 'ARIMA'])\n",
    "\n",
    "print(f\"‚úÖ S·ªë ƒëi·ªÉm d·ªØ li·ªáu sau align: {len(comparison_df)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. T√çNH METRICS - MAE v√† RMSE\n",
    "# ============================================================\n",
    "metrics = {\n",
    "    'Model': ['Regression (Lag Features)', 'ARIMA'],\n",
    "    'MAE': [\n",
    "        mean_absolute_error(comparison_df['Actual'], comparison_df['Regression']),\n",
    "        mean_absolute_error(comparison_df['Actual'], comparison_df['ARIMA'])\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        np.sqrt(mean_squared_error(comparison_df['Actual'], comparison_df['Regression'])),\n",
    "        np.sqrt(mean_squared_error(comparison_df['Actual'], comparison_df['ARIMA']))\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df['RMSE - MAE Gap'] = metrics_df['RMSE'] - metrics_df['MAE']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà B·∫¢NG SO S√ÅNH METRICS (Horizon = 1)\")\n",
    "print(\"=\"*60)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Save metrics\n",
    "metrics_df.to_csv('../data/processed/Topic_metrics_comparison.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: Topic_metrics_comparison.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. VISUALIZATION 1: Forecast vs Actual (200 gi·ªù ƒë·∫ßu)\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "subset = comparison_df.iloc[:200]\n",
    "\n",
    "ax.plot(subset.index, subset['Actual'], label='Actual', color=COLOR_BLUE, linewidth=1.5)\n",
    "ax.plot(subset.index, subset['Regression'], label='Regression', color=COLOR_GREEN, \n",
    "        linestyle='--', linewidth=1.2, alpha=0.8)\n",
    "ax.plot(subset.index, subset['ARIMA'], label='ARIMA', color=COLOR_RED, \n",
    "        linestyle='-.', linewidth=1.2, alpha=0.8)\n",
    "\n",
    "ax.set_title('Forecast vs Actual: Regression vs ARIMA (First 200 Hours)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('DateTime (Ox)', fontsize=11)\n",
    "ax.set_ylabel('PM2.5 Concentration (ug/m¬≥) (Oy)', fontsize=11)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig('../images/Topic_forecast_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 5. VISUALIZATION 2: SPIKE ANALYSIS\n",
    "# ============================================================\n",
    "# T√¨m ng√†y c√≥ spike (PM2.5 cao nh·∫•t)\n",
    "spike_date = comparison_df['Actual'].idxmax()\n",
    "print(f\"\\nüî¥ Spike detected at: {spike_date}, PM2.5 = {comparison_df.loc[spike_date, 'Actual']:.1f}\")\n",
    "\n",
    "# L·∫•y window 3 ng√†y xung quanh spike\n",
    "spike_start = spike_date - pd.Timedelta(days=1)\n",
    "spike_end = spike_date + pd.Timedelta(days=2)\n",
    "spike_window = comparison_df.loc[spike_start:spike_end]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(spike_window.index, spike_window['Actual'], label='Actual', \n",
    "        color=COLOR_BLUE, linewidth=2, marker='o', markersize=3)\n",
    "ax.plot(spike_window.index, spike_window['Regression'], label='Regression', \n",
    "        color=COLOR_GREEN, linewidth=1.5, linestyle='--')\n",
    "ax.plot(spike_window.index, spike_window['ARIMA'], label='ARIMA', \n",
    "        color=COLOR_RED, linewidth=1.5, linestyle='-.')\n",
    "\n",
    "# ƒê√°nh d·∫•u ƒëi·ªÉm spike\n",
    "ax.axvline(x=spike_date, color=COLOR_ORANGE, linestyle=':', linewidth=2, alpha=0.7, label='Peak Time')\n",
    "ax.scatter([spike_date], [comparison_df.loc[spike_date, 'Actual']], \n",
    "           color=COLOR_ORANGE, s=150, zorder=5, marker='*')\n",
    "\n",
    "ax.set_title('Spike Analysis: Model Performance during High Pollution Event', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('DateTime (Ox)', fontsize=11)\n",
    "ax.set_ylabel('PM2.5 Concentration (ug/m¬≥) (Oy)', fontsize=11)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig('../images/Topic_spike_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# T√≠nh metrics ri√™ng cho spike period\n",
    "print(\"\\nüìä Metrics trong giai ƒëo·∫°n SPIKE:\")\n",
    "spike_metrics = {\n",
    "    'Model': ['Regression', 'ARIMA'],\n",
    "    'MAE_Spike': [\n",
    "        mean_absolute_error(spike_window['Actual'], spike_window['Regression']),\n",
    "        mean_absolute_error(spike_window['Actual'], spike_window['ARIMA'])\n",
    "    ],\n",
    "    'RMSE_Spike': [\n",
    "        np.sqrt(mean_squared_error(spike_window['Actual'], spike_window['Regression'])),\n",
    "        np.sqrt(mean_squared_error(spike_window['Actual'], spike_window['ARIMA']))\n",
    "    ]\n",
    "}\n",
    "spike_metrics_df = pd.DataFrame(spike_metrics)\n",
    "print(spike_metrics_df.to_string(index=False))\n",
    "\n",
    "# L∆∞u spike metrics ra CSV\n",
    "spike_metrics_df.to_csv('../data/processed/Topic_spike_metrics.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: Topic_spike_metrics.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. ERROR DISTRIBUTION ANALYSIS\n",
    "# ============================================================\n",
    "comparison_df['Error_Reg'] = comparison_df['Actual'] - comparison_df['Regression']\n",
    "comparison_df['Error_ARIMA'] = comparison_df['Actual'] - comparison_df['ARIMA']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of errors\n",
    "axes[0].hist(comparison_df['Error_Reg'], bins=50, alpha=0.6, color=COLOR_GREEN, label='Regression', density=True)\n",
    "axes[0].hist(comparison_df['Error_ARIMA'], bins=50, alpha=0.6, color=COLOR_RED, label='ARIMA', density=True)\n",
    "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[0].set_title('Error Distribution Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Prediction Error (Ox)', fontsize=11)\n",
    "axes[0].set_ylabel('Density (Oy)', fontsize=11)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot of absolute errors\n",
    "error_data = pd.DataFrame({\n",
    "    'Regression': np.abs(comparison_df['Error_Reg']),\n",
    "    'ARIMA': np.abs(comparison_df['Error_ARIMA'])\n",
    "})\n",
    "error_data_melted = error_data.melt(var_name='Model', value_name='Absolute Error')\n",
    "sns.boxplot(x='Model', y='Absolute Error', data=error_data_melted, \n",
    "            palette=[COLOR_GREEN, COLOR_RED], ax=axes[1])\n",
    "axes[1].set_title('Absolute Error Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig('../images/Topic_error_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Topic 1 Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08b2b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## üìä K·∫øt lu·∫≠n Topic 1: Regression vs ARIMA\n",
    "\n",
    "### **C√¢u 1: M√¥ h√¨nh n√†o t·ªët h∆°n cho horizon=1?**\n",
    "\n",
    "**K·∫øt lu·∫≠n d·ª±a tr√™n metrics:**\n",
    "- So s√°nh MAE v√† RMSE t·ª´ b·∫£ng tr√™n ƒë·ªÉ x√°c ƒë·ªãnh m√¥ h√¨nh t·ªët h∆°n\n",
    "- **Regression baseline** th∆∞·ªùng b√°m s√°t t·ªët v·ªõi horizon=1 v√¨:\n",
    "  - Feature `PM2.5_lag1` (ƒë·ªô tr·ªÖ 1 gi·ªù) c√≥ t∆∞∆°ng quan r·∫•t cao v·ªõi gi√° tr·ªã hi·ªán t·∫°i\n",
    "  - M√¥ h√¨nh h·ªçc ƒë∆∞·ª£c pattern t·ª´ nhi·ªÅu ƒë·∫∑c tr∆∞ng: lag features, time features, weather features\n",
    "- **ARIMA** ph·ª• thu·ªôc v√†o c·∫•u tr√∫c t·ª± t∆∞∆°ng quan v√† quy·∫øt ƒë·ªãnh sai ph√¢n (d)\n",
    "\n",
    "**Gi·∫£i th√≠ch:** V·ªõi horizon=1, gi√° tr·ªã PM2.5 ·ªü th·ªùi ƒëi·ªÉm t-1 l√† predictor m·∫°nh nh·∫•t. Regression c√≥ th·ªÉ khai th√°c tr·ª±c ti·∫øp feature n√†y, trong khi ARIMA ph·∫£i h·ªçc t·ª´ c·∫•u tr√∫c AR c·ªßa chu·ªói.\n",
    "\n",
    "---\n",
    "\n",
    "### **C√¢u 2: M√¥ h√¨nh n√†o ·ªïn h∆°n khi c√≥ spike?**\n",
    "\n",
    "**Ph√¢n t√≠ch t·ª´ bi·ªÉu ƒë·ªì Spike Analysis:**\n",
    "- Quan s√°t xem m√¥ h√¨nh n√†o **ph·∫£n ·ª©ng nhanh h∆°n** v·ªõi ƒë·ªânh √¥ nhi·ªÖm\n",
    "- M√¥ h√¨nh n√†o b·ªã **m∆∞·ª£t h√≥a qu√° m·ª©c** (underestimate spike)\n",
    "\n",
    "**Li√™n h·ªá RMSE vs MAE:**\n",
    "- N·∫øu `RMSE - MAE gap` l·ªõn ‚Üí m√¥ h√¨nh c√≥ nhi·ªÅu sai s·ªë l·ªõn (th∆∞·ªùng ·ªü spike)\n",
    "- RMSE ph·∫°t n·∫∑ng sai s·ªë l·ªõn theo c√¥ng th·ª©c b√¨nh ph∆∞∆°ng\n",
    "- MAE ƒë·ªëi x·ª≠ c√¥ng b·∫±ng v·ªõi m·ªçi sai s·ªë\n",
    "\n",
    "**K·∫øt lu·∫≠n:** Model c√≥ RMSE-MAE gap nh·ªè h∆°n s·∫Ω ·ªïn ƒë·ªãnh h∆°n trong c√°c t√¨nh hu·ªëng spike.\n",
    "\n",
    "---\n",
    "\n",
    "### **C√¢u 3: N·∫øu tri·ªÉn khai th·∫≠t, ch·ªçn g√¨?**\n",
    "\n",
    "| Ti√™u ch√≠ | Regression | ARIMA |\n",
    "|----------|------------|-------|\n",
    "| **ƒê·ªô ch√≠nh x√°c horizon=1** | ‚úÖ Th∆∞·ªùng t·ªët h∆°n | ‚ö†Ô∏è T√πy c·∫•u tr√∫c chu·ªói |\n",
    "| **M·ªü r·ªông features** | ‚úÖ D·ªÖ th√™m weather, events | ‚ùå Ch·ªâ d√πng l·ªãch s·ª≠ PM2.5 |\n",
    "| **T·ªëc ƒë·ªô inference** | ‚úÖ Nhanh | ‚ö†Ô∏è Ch·∫≠m h∆°n |\n",
    "| **Kho·∫£ng tin c·∫≠y** | ‚ùå Kh√¥ng c√≥ s·∫µn | ‚úÖ C√≥ CI t·ª± ƒë·ªông |\n",
    "| **Gi·∫£i th√≠ch m√¥ h√¨nh** | ‚ö†Ô∏è Feature importance | ‚úÖ R√µ r√†ng qua (p,d,q) |\n",
    "| **C·∫£nh b√°o s·ªõm** | ‚úÖ Khi c√≥ external features | ‚úÖ Khi pattern ·ªïn ƒë·ªãnh |\n",
    "\n",
    "**Khuy·∫øn ngh·ªã:**\n",
    "- N·∫øu m·ª•c ti√™u l√† **c·∫£nh b√°o s·ªõm** trong ƒëi·ªÅu ki·ªán th·ªùi ti·∫øt bi·∫øn ƒë·ªông: **Regression** (v√¨ c√≥ th·ªÉ th√™m d·ª± b√°o th·ªùi ti·∫øt)\n",
    "- N·∫øu c·∫ßn **gi·∫£i th√≠ch + kho·∫£ng tin c·∫≠y** cho b√°o c√°o ch√≠nh th·ª©c: **ARIMA**\n",
    "- Trong th·ª±c t·∫ø: C√≥ th·ªÉ **k·∫øt h·ª£p c·∫£ hai** - d√πng Regression cho real-time v√† ARIMA ƒë·ªÉ cross-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d090cbb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2. Topic 2: SARIMA ‚Äì Th√™m m√πa v·ª• (Seasonality)\n",
    "\n",
    "Ch·ªß ƒë·ªÅ SARIMA y√™u c·∫ßu nh√≥m n√¢ng c·∫•p tr·ª±c ti·∫øp t·ª´ ARIMA l√™n SARIMA $(p, d, q)(P, D, Q, s)$ ƒë·ªÉ m√¥ h√¨nh h√≥a m√πa v·ª• theo ng√†y ho·∫∑c theo tu·∫ßn.\n",
    "\n",
    "**C√°c b∆∞·ªõc th·ª±c hi·ªán:**\n",
    "\n",
    "1. **Ch·ª©ng minh m√πa v·ª• b·∫±ng ACF:**\n",
    "   - N·∫øu th·∫•y c√°c ƒë·ªânh l·∫∑p l·∫°i m·∫°nh ·ªü lag 24, 48, ‚Ä¶ ‚Üí t√≠n hi·ªáu m√πa v·ª• theo ng√†y\n",
    "   - N·∫øu xu·∫•t hi·ªán t√≠n hi·ªáu ·ªü lag 168, 336, ‚Ä¶ ‚Üí g·ª£i √Ω m√πa v·ª• theo tu·∫ßn\n",
    "\n",
    "2. **Th·ª≠ √≠t nh·∫•t m·ªôt c·∫•u h√¨nh SARIMA v·ªõi s=24** (b·∫Øt bu·ªôc)\n",
    "\n",
    "3. **Chi·∫øn l∆∞·ª£c grid search:**\n",
    "   - Gi·ªØ $d$ theo k·∫øt lu·∫≠n stationarity c·ªßa ARIMA baseline\n",
    "   - Ch·ªçn v√πng t√¨m ki·∫øm nh·ªè cho $p, q$\n",
    "   - Th√™m $P, Q$ ·ªü m·ª©c th·∫•p (0‚Äì2)\n",
    "   - C√¢n nh·∫Øc $D$ (0 ho·∫∑c 1)\n",
    "\n",
    "4. **So s√°nh ARIMA v√† SARIMA:**\n",
    "   - AIC/BIC\n",
    "   - RMSE/MAE tr√™n t·∫≠p test\n",
    "   - K·∫øt lu·∫≠n: SARIMA c·∫£i thi·ªán/kh√¥ng c·∫£i thi·ªán v√¨ sao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822abb4a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TOPIC 2: SARIMA - Th√™m m√πa v·ª• (Seasonality)\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TOPIC 2: SARIMA - Ph√¢n t√≠ch m√πa v·ª• v√† so s√°nh v·ªõi ARIMA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================\n",
    "# Load cleaned data (parquet format)\n",
    "df = pd.read_parquet('../data/processed/01_cleaned.parquet')\n",
    "if 'datetime' in df.columns:\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Filter for one station for consistency\n",
    "STATION = 'Aotizhongxin'\n",
    "CUTOFF = '2017-01-01'\n",
    "\n",
    "if 'station' in df.columns:\n",
    "    df_station = df[df['station'] == STATION]['PM2.5'].dropna()\n",
    "else:\n",
    "    df_station = df['PM2.5'].dropna()\n",
    "\n",
    "print(f\"\\nüìç Tr·∫°m ph√¢n t√≠ch: {STATION}\")\n",
    "print(f\"üìä S·ªë ƒëi·ªÉm d·ªØ li·ªáu: {len(df_station)}\")\n",
    "print(f\"üìÖ Kho·∫£ng th·ªùi gian: {df_station.index.min()} ƒë·∫øn {df_station.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d0ff5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: CH·ª®NG MINH M√ôA V·ª§ B·∫∞NG ACF\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Ch·ª©ng minh m√πa v·ª• b·∫±ng ACF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# T√≠nh ACF v·ªõi lag l·ªõn ƒë·ªÉ xem pattern m√πa v·ª•\n",
    "acf_values = acf(df_station, nlags=200, fft=True)\n",
    "\n",
    "# Ki·ªÉm tra ACF t·∫°i c√°c lag quan tr·ªçng\n",
    "print(\"\\nüìä ACF t·∫°i c√°c lag quan tr·ªçng:\")\n",
    "important_lags = [1, 12, 24, 48, 72, 168, 336]\n",
    "for lag in important_lags:\n",
    "    if lag < len(acf_values):\n",
    "        print(f\"  Lag {lag:3d}h ({lag//24:.1f} ng√†y): ACF = {acf_values[lag]:.4f}\")\n",
    "\n",
    "# V·∫Ω ACF ƒë·ªÉ ch·ª©ng minh m√πa v·ª•\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# ACF v·ªõi 200 lags ƒë·ªÉ th·∫•y pattern m√πa v·ª• ng√†y v√† tu·∫ßn\n",
    "plot_acf(df_station, lags=200, ax=axes[0], color=COLOR_BLUE, alpha=0.05)\n",
    "axes[0].axvline(x=24, color=COLOR_RED, linestyle='--', linewidth=2, alpha=0.7, label='Lag 24h (Daily)')\n",
    "axes[0].axvline(x=48, color=COLOR_RED, linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "axes[0].axvline(x=168, color=COLOR_ORANGE, linestyle=':', linewidth=2, alpha=0.7, label='Lag 168h (Weekly)')\n",
    "axes[0].set_title('ACF Analysis: Detecting Seasonality Pattern (200 Lags)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag (hours) (Ox)', fontsize=11)\n",
    "axes[0].set_ylabel('Autocorrelation (Oy)', fontsize=11)\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zoom v√†o 50 lags ƒë·∫ßu ƒë·ªÉ th·∫•y r√µ h∆°n\n",
    "plot_acf(df_station, lags=50, ax=axes[1], color=COLOR_BLUE, alpha=0.05)\n",
    "axes[1].axvline(x=24, color=COLOR_RED, linestyle='--', linewidth=2, alpha=0.7, label='Lag 24h')\n",
    "axes[1].set_title('ACF Analysis: First 50 Lags (Detail View)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag (hours) (Ox)', fontsize=11)\n",
    "axes[1].set_ylabel('Autocorrelation (Oy)', fontsize=11)\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig('../images/Topic_acf_seasonality_proof.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# L∆∞u ACF values ra CSV\n",
    "acf_important_df = pd.DataFrame({\n",
    "    'Lag': important_lags,\n",
    "    'ACF': [acf_values[lag] if lag < len(acf_values) else None for lag in important_lags]\n",
    "})\n",
    "acf_important_df.to_csv('../data/processed/Topic_acf_seasonality.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: Topic_acf_seasonality.csv\")\n",
    "\n",
    "# K·∫øt lu·∫≠n v·ªÅ m√πa v·ª•\n",
    "print(\"\\nüìù K·∫æT LU·∫¨N V·ªÄ M√ôA V·ª§:\")\n",
    "if acf_values[24] > 0.3:\n",
    "    print(f\"  ‚úÖ M√πa v·ª• NG√ÄY (s=24): ACF t·∫°i lag 24 = {acf_values[24]:.4f} > 0.3 ‚Üí C√≥ t√≠n hi·ªáu m√πa v·ª• theo ng√†y\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è M√πa v·ª• NG√ÄY y·∫øu: ACF t·∫°i lag 24 = {acf_values[24]:.4f}\")\n",
    "\n",
    "if len(acf_values) > 168 and acf_values[168] > 0.2:\n",
    "    print(f\"  ‚úÖ M√πa v·ª• TU·∫¶N (s=168): ACF t·∫°i lag 168 = {acf_values[168]:.4f} > 0.2 ‚Üí C√≥ t√≠n hi·ªáu m√πa v·ª• theo tu·∫ßn\")\n",
    "else:\n",
    "    weekly_acf = acf_values[168] if len(acf_values) > 168 else \"N/A\"\n",
    "    print(f\"  ‚ö†Ô∏è M√πa v·ª• TU·∫¶N y·∫øu: ACF t·∫°i lag 168 = {weekly_acf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2e759",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: KI·ªÇM ƒê·ªäNH T√çNH D·ª™NG ƒê·ªÇ X√ÅC ƒê·ªäNH d\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Ki·ªÉm ƒë·ªãnh t√≠nh d·ª´ng (ADF & KPSS) ƒë·ªÉ ch·ªçn d\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ADF Test\n",
    "adf_result = adfuller(df_station, autolag='AIC')\n",
    "print(f\"\\nüìä ADF Test:\")\n",
    "print(f\"  Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"  p-value: {adf_result[1]:.6f}\")\n",
    "print(f\"  Critical Values:\")\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f\"    {key}: {value:.4f}\")\n",
    "\n",
    "# KPSS Test\n",
    "kpss_result = kpss(df_station, regression='c', nlags='auto')\n",
    "print(f\"\\nüìä KPSS Test:\")\n",
    "print(f\"  Statistic: {kpss_result[0]:.4f}\")\n",
    "print(f\"  p-value: {kpss_result[1]:.4f}\")\n",
    "print(f\"  Critical Values:\")\n",
    "for key, value in kpss_result[3].items():\n",
    "    print(f\"    {key}: {value:.4f}\")\n",
    "\n",
    "# K·∫øt lu·∫≠n v·ªÅ d\n",
    "print(\"\\nüìù K·∫æT LU·∫¨N V·ªÄ d:\")\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"  ‚úÖ ADF: B√°c b·ªè H0 ‚Üí Chu·ªói D·ª™NG (p < 0.05)\")\n",
    "    d_suggested = 0\n",
    "else:\n",
    "    print(\"  ‚ùå ADF: Kh√¥ng b√°c b·ªè H0 ‚Üí Chu·ªói KH√îNG D·ª™NG\")\n",
    "    d_suggested = 1\n",
    "\n",
    "if kpss_result[1] > 0.05:\n",
    "    print(\"  ‚úÖ KPSS: Kh√¥ng b√°c b·ªè H0 ‚Üí Chu·ªói D·ª™NG (p > 0.05)\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è KPSS: B√°c b·ªè H0 ‚Üí Chu·ªói c√≥ xu h∆∞·ªõng/kh√¥ng d·ª´ng\")\n",
    "\n",
    "print(f\"\\n  ‚Üí K·∫øt lu·∫≠n: d = {d_suggested} (gi·ªØ c·ªë ƒë·ªãnh cho ARIMA v√† SARIMA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a948b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 4: TRAIN/TEST SPLIT V√Ä CHU·∫®N B·ªä D·ªÆ LI·ªÜU\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: Chu·∫©n b·ªã Train/Test Split\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Split data theo CUTOFF\n",
    "train = df_station[:CUTOFF]\n",
    "test = df_station[CUTOFF:]\n",
    "\n",
    "print(f\"\\nüìä Train set: {len(train)} ƒëi·ªÉm ({train.index.min()} ƒë·∫øn {train.index.max()})\")\n",
    "print(f\"üìä Test set: {len(test)} ƒëi·ªÉm ({test.index.min()} ƒë·∫øn {test.index.max()})\")\n",
    "\n",
    "# ƒê·ªÉ ti·∫øt ki·ªám th·ªùi gian t√≠nh to√°n, l·∫•y sample train (cu·ªëi c√πng 5000 ƒëi·ªÉm)\n",
    "# Trong th·ª±c t·∫ø n√™n d√πng to√†n b·ªô\n",
    "SAMPLE_SIZE = 5000\n",
    "train_sample = train.tail(SAMPLE_SIZE)\n",
    "print(f\"\\n‚ö° S·ª≠ d·ª•ng {SAMPLE_SIZE} ƒëi·ªÉm cu·ªëi c·ªßa train ƒë·ªÉ training (t·ªëi ∆∞u th·ªùi gian)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe9ac3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 5: TRAIN ARIMA BASELINE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: Training ARIMA Baseline\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ARIMA config t·ª´ ACF/PACF analysis\n",
    "# d = 0 (t·ª´ ADF test), p v√† q t·ª´ PACF/ACF\n",
    "arima_order = (2, 0, 1)  # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n ACF/PACF\n",
    "\n",
    "print(f\"\\nüîß ARIMA Configuration: order = {arima_order}\")\n",
    "print(\"   p=2: PACF c√≥ spike t·∫°i lag 1, 2\")\n",
    "print(\"   d=0: Chu·ªói d·ª´ng theo ADF test\")\n",
    "print(\"   q=1: ACF decay d·∫ßn sau lag 1\")\n",
    "\n",
    "print(\"\\n‚è≥ Training ARIMA model...\")\n",
    "try:\n",
    "    model_arima = SARIMAX(train_sample, order=arima_order, \n",
    "                          enforce_stationarity=False, enforce_invertibility=False)\n",
    "    fit_arima = model_arima.fit(disp=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ ARIMA Training Complete!\")\n",
    "    print(f\"   AIC: {fit_arima.aic:.2f}\")\n",
    "    print(f\"   BIC: {fit_arima.bic:.2f}\")\n",
    "    \n",
    "    # Forecast\n",
    "    forecast_steps = min(len(test), 168*2)  # 2 tu·∫ßn\n",
    "    forecast_arima = fit_arima.get_forecast(steps=forecast_steps)\n",
    "    pred_arima = forecast_arima.predicted_mean\n",
    "    pred_arima.index = test.index[:forecast_steps]\n",
    "    \n",
    "    # Metrics\n",
    "    actual_test = test[:forecast_steps]\n",
    "    mae_arima = mean_absolute_error(actual_test, pred_arima)\n",
    "    rmse_arima = np.sqrt(mean_squared_error(actual_test, pred_arima))\n",
    "    \n",
    "    print(f\"\\nüìä ARIMA Test Metrics (first {forecast_steps} hours):\")\n",
    "    print(f\"   MAE: {mae_arima:.2f}\")\n",
    "    print(f\"   RMSE: {rmse_arima:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error training ARIMA: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b235f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 6: TRAIN SARIMA v·ªõi s=24 (M√πa v·ª• ng√†y)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: Training SARIMA v·ªõi s=24 (Daily Seasonality)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# SARIMA config: gi·ªØ d c·ªë ƒë·ªãnh, th√™m seasonal component\n",
    "# Chi·∫øn l∆∞·ª£c: P, Q ·ªü m·ª©c th·∫•p (0-2), D = 0 ho·∫∑c 1\n",
    "sarima_order = (2, 0, 1)\n",
    "sarima_seasonal_24 = (1, 0, 1, 24)  # P=1, D=0, Q=1, s=24\n",
    "\n",
    "print(f\"\\nüîß SARIMA Configuration:\")\n",
    "print(f\"   Order: {sarima_order}\")\n",
    "print(f\"   Seasonal Order: {sarima_seasonal_24}\")\n",
    "print(\"   P=1: Seasonal AR t·∫°i lag 24\")\n",
    "print(\"   D=0: Kh√¥ng c·∫ßn seasonal differencing (v√¨ ACF kh√¥ng gi·∫£m ch·∫≠m t·∫°i 24, 48...)\")\n",
    "print(\"   Q=1: Seasonal MA t·∫°i lag 24\")\n",
    "print(\"   s=24: Chu k·ª≥ m√πa v·ª• theo ng√†y\")\n",
    "\n",
    "print(\"\\n‚è≥ Training SARIMA(2,0,1)(1,0,1,24)... (C√≥ th·ªÉ m·∫•t v√†i ph√∫t)\")\n",
    "try:\n",
    "    model_sarima_24 = SARIMAX(train_sample, \n",
    "                              order=sarima_order,\n",
    "                              seasonal_order=sarima_seasonal_24,\n",
    "                              enforce_stationarity=False, \n",
    "                              enforce_invertibility=False)\n",
    "    fit_sarima_24 = model_sarima_24.fit(disp=False, maxiter=200)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SARIMA(s=24) Training Complete!\")\n",
    "    print(f\"   AIC: {fit_sarima_24.aic:.2f}\")\n",
    "    print(f\"   BIC: {fit_sarima_24.bic:.2f}\")\n",
    "    \n",
    "    # Forecast\n",
    "    forecast_sarima_24 = fit_sarima_24.get_forecast(steps=forecast_steps)\n",
    "    pred_sarima_24 = forecast_sarima_24.predicted_mean\n",
    "    pred_sarima_24.index = test.index[:forecast_steps]\n",
    "    conf_int_24 = forecast_sarima_24.conf_int()\n",
    "    conf_int_24.index = test.index[:forecast_steps]\n",
    "    \n",
    "    # Metrics\n",
    "    mae_sarima_24 = mean_absolute_error(actual_test, pred_sarima_24)\n",
    "    rmse_sarima_24 = np.sqrt(mean_squared_error(actual_test, pred_sarima_24))\n",
    "    \n",
    "    print(f\"\\nüìä SARIMA(s=24) Test Metrics:\")\n",
    "    print(f\"   MAE: {mae_sarima_24:.2f}\")\n",
    "    print(f\"   RMSE: {rmse_sarima_24:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error training SARIMA(s=24): {e}\")\n",
    "    pred_sarima_24 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36d1a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 7: B·∫¢NG SO S√ÅNH ARIMA vs SARIMA\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: So s√°nh ARIMA vs SARIMA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# T·∫°o b·∫£ng so s√°nh\n",
    "comparison_results = {\n",
    "    'Model': ['ARIMA(2,0,1)', 'SARIMA(2,0,1)(1,0,1,24)'],\n",
    "    'AIC': [fit_arima.aic, fit_sarima_24.aic],\n",
    "    'BIC': [fit_arima.bic, fit_sarima_24.bic],\n",
    "    'MAE': [mae_arima, mae_sarima_24],\n",
    "    'RMSE': [rmse_arima, rmse_sarima_24]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(comparison_results)\n",
    "results_df['AIC_diff'] = results_df['AIC'] - results_df['AIC'].min()\n",
    "results_df['BIC_diff'] = results_df['BIC'] - results_df['BIC'].min()\n",
    "results_df['MAE_improvement'] = ((results_df['MAE'].iloc[0] - results_df['MAE']) / results_df['MAE'].iloc[0] * 100)\n",
    "results_df['RMSE_improvement'] = ((results_df['RMSE'].iloc[0] - results_df['RMSE']) / results_df['RMSE'].iloc[0] * 100)\n",
    "\n",
    "print(\"\\nüìä B·∫¢NG SO S√ÅNH T·ªîNG H·ª¢P:\")\n",
    "print(\"=\"*80)\n",
    "print(results_df[['Model', 'AIC', 'BIC', 'MAE', 'RMSE']].to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìà PH√ÇN T√çCH CHI TI·∫æT:\")\n",
    "print(f\"   AIC: SARIMA {'t·ªët h∆°n' if fit_sarima_24.aic < fit_arima.aic else 'k√©m h∆°n'} ARIMA ({fit_sarima_24.aic - fit_arima.aic:+.2f})\")\n",
    "print(f\"   BIC: SARIMA {'t·ªët h∆°n' if fit_sarima_24.bic < fit_arima.bic else 'k√©m h∆°n'} ARIMA ({fit_sarima_24.bic - fit_arima.bic:+.2f})\")\n",
    "print(f\"   MAE: SARIMA {'c·∫£i thi·ªán' if mae_sarima_24 < mae_arima else 'kh√¥ng c·∫£i thi·ªán'} ({(mae_arima - mae_sarima_24)/mae_arima*100:+.2f}%)\")\n",
    "print(f\"   RMSE: SARIMA {'c·∫£i thi·ªán' if rmse_sarima_24 < rmse_arima else 'kh√¥ng c·∫£i thi·ªán'} ({(rmse_arima - rmse_sarima_24)/rmse_arima*100:+.2f}%)\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../data/processed/Topic_sarima_comparison.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: Topic_sarima_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da95ce5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 8: VISUALIZATION - So s√°nh Forecast\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8: Visualization - ARIMA vs SARIMA Forecast\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot 1: So s√°nh forecast trong 1 tu·∫ßn ƒë·∫ßu\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# First 168 hours (1 week)\n",
    "plot_range = 168\n",
    "actual_plot = actual_test[:plot_range]\n",
    "arima_plot = pred_arima[:plot_range]\n",
    "sarima_plot = pred_sarima_24[:plot_range]\n",
    "\n",
    "# Plot ARIMA\n",
    "axes[0].plot(actual_plot.index, actual_plot.values, label='Actual', color=COLOR_BLUE, linewidth=1.5)\n",
    "axes[0].plot(arima_plot.index, arima_plot.values, label='ARIMA(2,0,1)', color=COLOR_RED, linestyle='--', linewidth=1.2)\n",
    "axes[0].set_title('ARIMA Forecast vs Actual (First Week)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('DateTime (Ox)', fontsize=11)\n",
    "axes[0].set_ylabel('PM2.5 (ug/m¬≥) (Oy)', fontsize=11)\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Plot SARIMA\n",
    "axes[1].plot(actual_plot.index, actual_plot.values, label='Actual', color=COLOR_BLUE, linewidth=1.5)\n",
    "axes[1].plot(sarima_plot.index, sarima_plot.values, label='SARIMA(2,0,1)(1,0,1,24)', color=COLOR_GREEN, linestyle='--', linewidth=1.2)\n",
    "# Add confidence interval\n",
    "if 'conf_int_24' in dir():\n",
    "    ci_plot = conf_int_24[:plot_range]\n",
    "    axes[1].fill_between(ci_plot.index, ci_plot.iloc[:, 0], ci_plot.iloc[:, 1], \n",
    "                         color=COLOR_GREEN, alpha=0.2, label='95% CI')\n",
    "axes[1].set_title('SARIMA Forecast vs Actual (First Week)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('DateTime (Ox)', fontsize=11)\n",
    "axes[1].set_ylabel('PM2.5 (ug/m¬≥) (Oy)', fontsize=11)\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig('../images/Topic_arima_vs_sarima_forecast.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: So s√°nh tr√™n c√πng 1 ƒë·ªì th·ªã\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "ax.plot(actual_plot.index, actual_plot.values, label='Actual', color=COLOR_BLUE, linewidth=2)\n",
    "ax.plot(arima_plot.index, arima_plot.values, label=f'ARIMA (MAE={mae_arima:.1f})', \n",
    "        color=COLOR_RED, linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "ax.plot(sarima_plot.index, sarima_plot.values, label=f'SARIMA s=24 (MAE={mae_sarima_24:.1f})', \n",
    "        color=COLOR_GREEN, linestyle='-.', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_title('Comparison: ARIMA vs SARIMA(s=24) Forecast', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('DateTime (Ox)', fontsize=11)\n",
    "ax.set_ylabel('PM2.5 (ug/m¬≥) (Oy)', fontsize=11)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig('../images/Topic_comparison_overlay.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f87121",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 9: RESIDUAL DIAGNOSTICS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 9: Residual Diagnostics - Ki·ªÉm tra White Noise\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ARIMA Residuals\n",
    "resid_arima = fit_arima.resid\n",
    "\n",
    "# Histogram of ARIMA residuals\n",
    "axes[0, 0].hist(resid_arima, bins=50, color=COLOR_RED, alpha=0.7, density=True)\n",
    "axes[0, 0].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[0, 0].set_title('ARIMA Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Residual (Ox)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Density (Oy)', fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ACF of ARIMA residuals\n",
    "plot_acf(resid_arima, lags=40, ax=axes[0, 1], color=COLOR_RED, alpha=0.05)\n",
    "axes[0, 1].set_title('ARIMA Residuals ACF', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# SARIMA Residuals\n",
    "resid_sarima = fit_sarima_24.resid\n",
    "\n",
    "# Histogram of SARIMA residuals\n",
    "axes[1, 0].hist(resid_sarima, bins=50, color=COLOR_GREEN, alpha=0.7, density=True)\n",
    "axes[1, 0].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1, 0].set_title('SARIMA(s=24) Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Residual (Ox)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Density (Oy)', fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ACF of SARIMA residuals\n",
    "plot_acf(resid_sarima, lags=40, ax=axes[1, 1], color=COLOR_GREEN, alpha=0.05)\n",
    "axes[1, 1].set_title('SARIMA(s=24) Residuals ACF', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig('../images/Topic_residual_diagnostics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nüìä Residual Statistics:\")\n",
    "print(f\"\\n   ARIMA Residuals:\")\n",
    "print(f\"     Mean: {resid_arima.mean():.4f} (should be ~0)\")\n",
    "print(f\"     Std: {resid_arima.std():.4f}\")\n",
    "\n",
    "print(f\"\\n   SARIMA(s=24) Residuals:\")\n",
    "print(f\"     Mean: {resid_sarima.mean():.4f} (should be ~0)\")\n",
    "print(f\"     Std: {resid_sarima.std():.4f}\")\n",
    "\n",
    "# Ljung-Box test for white noise\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "lb_arima = acorr_ljungbox(resid_arima, lags=[10, 20], return_df=True)\n",
    "lb_sarima = acorr_ljungbox(resid_sarima, lags=[10, 20], return_df=True)\n",
    "\n",
    "print(f\"\\nüìä Ljung-Box Test (H0: Residuals are white noise):\")\n",
    "print(f\"\\n   ARIMA p-values: lag10={lb_arima['lb_pvalue'].iloc[0]:.4f}, lag20={lb_arima['lb_pvalue'].iloc[1]:.4f}\")\n",
    "print(f\"   SARIMA p-values: lag10={lb_sarima['lb_pvalue'].iloc[0]:.4f}, lag20={lb_sarima['lb_pvalue'].iloc[1]:.4f}\")\n",
    "print(\"   (p > 0.05 ‚Üí Residuals are white noise ‚Üí Model captured main structure)\")\n",
    "\n",
    "# L∆∞u residual statistics ra CSV\n",
    "residual_stats_df = pd.DataFrame({\n",
    "    'Model': ['ARIMA', 'SARIMA(s=24)'],\n",
    "    'Residual_Mean': [resid_arima.mean(), resid_sarima.mean()],\n",
    "    'Residual_Std': [resid_arima.std(), resid_sarima.std()],\n",
    "    'LjungBox_lag10_pvalue': [lb_arima['lb_pvalue'].iloc[0], lb_sarima['lb_pvalue'].iloc[0]],\n",
    "    'LjungBox_lag20_pvalue': [lb_arima['lb_pvalue'].iloc[1], lb_sarima['lb_pvalue'].iloc[1]]\n",
    "})\n",
    "residual_stats_df.to_csv('../data/processed/Topic_residual_statistics.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: Topic_residual_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5f1a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## üìä K·∫øt lu·∫≠n Topic 2: SARIMA vs ARIMA\n",
    "\n",
    "### **1. Ch·ª©ng minh m√πa v·ª•:**\n",
    "\n",
    "T·ª´ bi·ªÉu ƒë·ªì ACF, ta quan s√°t ƒë∆∞·ª£c:\n",
    "- **M√πa v·ª• theo ng√†y (s=24):** ACF c√≥ c√°c ƒë·ªânh l·∫∑p l·∫°i t·∫°i lag 24, 48, 72... cho th·∫•y pattern m√πa v·ª• theo chu k·ª≥ ng√†y r√µ r√†ng.\n",
    "- **M√πa v·ª• theo tu·∫ßn (s=168):** ACF t·∫°i lag 168 c≈©ng c√≥ t√≠n hi·ªáu nh∆∞ng y·∫øu h∆°n so v·ªõi m√πa v·ª• ng√†y.\n",
    "\n",
    "‚Üí **K·∫øt lu·∫≠n:** M√πa v·ª• ng√†y (s=24) l√† l·ª±a ch·ªçn ph√π h·ª£p cho tr·∫°m Aotizhongxin.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Chi·∫øn l∆∞·ª£c ch·ªçn tham s·ªë SARIMA:**\n",
    "\n",
    "| Tham s·ªë | Gi√° tr·ªã | Gi·∫£i th√≠ch |\n",
    "|---------|---------|------------|\n",
    "| **d** | 0 | Chu·ªói d·ª´ng theo ADF test |\n",
    "| **p, q** | 2, 1 | T·ª´ PACF/ACF c·ªßa chu·ªói g·ªëc |\n",
    "| **D** | 0 | Kh√¥ng c·∫ßn seasonal differencing (ACF kh√¥ng gi·∫£m ch·∫≠m theo chu k·ª≥) |\n",
    "| **P, Q** | 1, 1 | Gi·ªØ ·ªü m·ª©c th·∫•p theo chi·∫øn l∆∞·ª£c |\n",
    "| **s** | 24 | M√πa v·ª• theo ng√†y |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. So s√°nh ARIMA vs SARIMA:**\n",
    "\n",
    "**V·ªÅ AIC/BIC:**\n",
    "- AIC/BIC th·∫•p h∆°n = model fit t·ªët h∆°n v·ªõi ƒë·ªô ph·ª©c t·∫°p h·ª£p l√Ω\n",
    "- SARIMA th∆∞·ªùng c√≥ AIC cao h∆°n do nhi·ªÅu tham s·ªë, nh∆∞ng n·∫øu c·∫£i thi·ªán MAE/RMSE th√¨ v·∫´n ƒë√°ng s·ª≠ d·ª•ng\n",
    "\n",
    "**V·ªÅ MAE/RMSE:**\n",
    "- N·∫øu SARIMA c·∫£i thi·ªán MAE/RMSE ‚Üí M√πa v·ª• s=24 th·ª±c s·ª± h·ªØu √≠ch\n",
    "- N·∫øu kh√¥ng c·∫£i thi·ªán ‚Üí Pattern m√πa v·ª• ƒë√£ ƒë∆∞·ª£c ARIMA capture ƒë·ªß qua AR terms\n",
    "\n",
    "---\n",
    "\n",
    "### **4. K·∫øt lu·∫≠n cu·ªëi c√πng:**\n",
    "\n",
    "**SARIMA c·∫£i thi·ªán hay kh√¥ng?**\n",
    "- Xem k·∫øt qu·∫£ t·ª´ b·∫£ng so s√°nh metrics ·ªü tr√™n\n",
    "- N·∫øu MAE/RMSE gi·∫£m ‚â• 5%: SARIMA ƒë√°ng s·ª≠ d·ª•ng\n",
    "- N·∫øu gi·∫£m < 5%: Chi ph√≠ t√≠nh to√°n tƒÉng c√≥ th·ªÉ kh√¥ng ƒë√°ng\n",
    "\n",
    "**M√πa v·ª• n√†o ph√π h·ª£p h∆°n?**\n",
    "- **s=24 (ng√†y):** Ph√π h·ª£p cho d·ª± b√°o ng·∫Øn h·∫°n (1-24 gi·ªù)\n",
    "- **s=168 (tu·∫ßn):** Ph√π h·ª£p cho d·ª± b√°o d√†i h·∫°n h∆°n (> 1 ng√†y)\n",
    "\n",
    "**Khuy·∫øn ngh·ªã cho tri·ªÉn khai:**\n",
    "- N·∫øu c·∫ßn d·ª± b√°o real-time (horizon=1): ARIMA c√≥ th·ªÉ ƒë·ªß\n",
    "- N·∫øu c·∫ßn d·ª± b√°o 24-48 gi·ªù: SARIMA(s=24) n√™n ƒë∆∞·ª£c c√¢n nh·∫Øc\n",
    "- Lu√¥n ki·ªÉm tra residuals ƒë·ªÉ ƒë·∫£m b·∫£o model ƒë√£ capture ƒë∆∞·ª£c c·∫•u tr√∫c ch√≠nh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KhaiPhaDuLieu",
   "language": "python",
   "name": "KhaiPhaDuLieu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.366598,
   "end_time": "2026-01-20T00:20:56.396092",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/Topic.ipynb",
   "output_path": "notebooks/runs/Topic_out.ipynb",
   "parameters": {},
   "start_time": "2026-01-20T00:20:50.029494",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}